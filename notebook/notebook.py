# -*- coding: utf-8 -*-
"""audioDL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ekm1Y71KbbuNm_jsXZTlOxcPcjAQ_JOz

# <center> **Vietnamese Traditional Music Classification (Deep Learning Approach)**</center>
"""

from google.colab import drive
drive.mount('/content/drive')

# Define root directory
root = '/content/drive/MyDrive/DATA/VNTM3'
folder_root = "/content/drive/MyDrive/DATA/mel-images"
dataset_root = "/content/drive/MyDrive/DATA/dataset"
train_root = "/content/drive/MyDrive/DATA/train"
val_root = "/content/drive/MyDrive/DATA/val"
test_root = "/content/drive/MyDrive/DATA/test"
checkpoint_filepath = '/content/drive/MyDrive/DATA/checkpoint'
saved_model_path = '/content/drive/MyDrive/DATA/model'
test_audio_path = "/content/drive/MyDrive/DATA/test_audio"

import os
import librosa as lb
import numpy as np
import IPython.display as ipd
import matplotlib.pyplot as plt
import random

os.listdir(root)

# Define variables for further use
type_list = {0: ["cailuong", "CaiLuong"], 1: ["catru", "Catru"], 2:["chauvan", "Chauvan"], 3: ["cheo", "Cheo"], 4: ["hatxam", "Xam"]}
class_list = {0: "cailuong", 1: "catru", 2:"chauvan", 3: "cheo", 4: "hatxam"}

"""## 1) **Data Preprocessing**

For each class, we create a dictionary which keys are the numerical order (index) of samples in the folder of that class, and value corresponding to the index is another dictionary containing necessary  properties sush as directory, sampling array, short-time fourier transfrom, spectrogram ...

Here is example of the dictionary of samplesin "cailuong" folder:

In this part, we create two dictionary for each class:
 - ```five_class_samples:``` Dictionary of 5 random samples of the class for the purpose of debugging and visualization.
 - ```class_samples:``` Dictionary all samples of the class.

### **Get directories**
"""

# Function t
def load_dir_samples(root, type_index, samples_list, num_of_samples, mode):
    # Mode:
    #   - Random: Load random dir
    #   - All: Load all dir

    # Return:
    #   - Sample_list: Dictionary {index: {"dir": "/...."}}
    def padding(index):
        # Padding
        if 0 <= index < 10:
            index = "00" +str(index)
        elif 10 <= index < 100:
            index = "0" +str(index)
        return index
    for i in range(0, num_of_samples):
        if mode == "random": # Mode load random samples
            random_index = np.random.randint(0, 500)
            index = random_index
            samples_list[index] = {}  # For futher append values
            random_index = padding(random_index)
            samples_list[index]["dir"] = (os.path.join(root, type_list[type_index][0], type_list[type_index][1] + "." + str(random_index) + ".wav"))
        if mode == "all":  # Mode load all samples
            index = i
            samples_list[index] = {}
            i = padding(i)
            samples_list[index]["dir"] = os.path.join(root, type_list[type_index][0], type_list[type_index][1] + "." + str(i) + ".wav")
    return samples_list

"""#### Get random 5 samples directory and audio"""

# Get 5 samples of class "Cailuong"
five_cailuong_samples = load_dir_samples(root, 0, {}, 5, "random")
print(five_cailuong_samples)
# Take a sample
key = list(five_cailuong_samples.keys())
print("Sample id: {}".format(key[0]))
ipd.Audio(five_cailuong_samples[key[0]]["dir"])

# Get 5 samples of class "Catru"
five_catru_samples = load_dir_samples(root, 1, {}, 5, "random")
print(five_catru_samples)
# Take a sample
key = list(five_catru_samples.keys())
print("Sample id: {}".format(key[0]))
ipd.Audio(five_catru_samples[key[0]]["dir"])

# Get 5 samples of class "chauvan"
five_chauvan_samples = load_dir_samples(root, 2, {}, 5, "random")
print(five_chauvan_samples)
# Take a sample
key = list(five_chauvan_samples.keys())
print("Sample id: {}".format(key[0]))
ipd.Audio(five_chauvan_samples[key[0]]["dir"])

# Get 5 samples of class "cheo"
five_cheo_samples = load_dir_samples(root, 3, {}, 5, "random")
print(five_cheo_samples)
# Take a sample
key = list(five_cheo_samples.keys())
print("Sample id: {}".format(key[0]))
ipd.Audio(five_cheo_samples[key[0]]["dir"])

# Get 5 samples of class "hatxam"
five_hatxam_samples = load_dir_samples(root, 4, {}, 5, "random")
print(five_hatxam_samples)
# Take a sample
key = list(five_hatxam_samples.keys())
print("Sample id: {}".format(key[0]))
ipd.Audio(five_hatxam_samples[key[0]]["dir"])

"""#### Get all samples directory"""

# Load all samples of class "cailuong"
nums_of_cailuong_samples = len(os.listdir(root+ "/cailuong"))
cailuong_samples = load_dir_samples(root, 0, {}, nums_of_cailuong_samples, mode = "all")
print(cailuong_samples)
len(cailuong_samples) # 500 samples

# Load all samples of class "catru"
nums_of_catru_samples = len(os.listdir(root+ "/catru"))
catru_samples = load_dir_samples(root, 1, {}, nums_of_catru_samples, mode = "all")
print(catru_samples)
len(catru_samples)

# Load all samples of class "chauvan"
nums_of_chauvan_samples = len(os.listdir(root+ "/chauvan"))
chauvan_samples = load_dir_samples(root, 2, {}, nums_of_chauvan_samples, mode = "all")
print(chauvan_samples)
len(chauvan_samples)

# Load all samples of class "cheo"
nums_of_cheo_samples = len(os.listdir(root+ "/cheo"))
cheo_samples = load_dir_samples(root, 3, {}, nums_of_cheo_samples, mode = "all")
print(cheo_samples)
len(cheo_samples)

# Load all samples of class "hatxam"
nums_of_hatxam_samples = len(os.listdir(root+ "/hatxam"))
hatxam_samples = load_dir_samples(root, 4, {}, nums_of_hatxam_samples, mode = "all")
print(hatxam_samples)
len(hatxam_samples)

"""### **Sampling**"""

# Function to get signal sampling
def load_samples(samples_listdir):
    """
    Load and sampling
    Input: samples_listdir - Dictionary {index: {"dir": "/...."}}
    Output: samples_listdir - Dictionary {index: {"dir": "/....", "sampling": array}}
    """
    for index, sample in samples_listdir.items():
        file, sr = lb.load(sample["dir"])
        if len(samples_listdir[index]) == 1:  # Avoid adding multiple times
            samples_listdir[index]["sampling"] = file
    return samples_listdir

"""#### Sampling 5 random samples"""

five_cailuong_samples = load_samples(five_cailuong_samples)
print(five_cailuong_samples)

five_catru_samples = load_samples(five_catru_samples)
print(five_catru_samples)

five_chauvan_samples = load_samples(five_chauvan_samples)
print(five_chauvan_samples)

five_cheo_samples = load_samples(five_cheo_samples)
print(five_cheo_samples)

five_hatxam_samples = load_samples(five_hatxam_samples)
print(five_hatxam_samples)

"""#### Sampling all samples"""

cailuong_samples = load_samples(cailuong_samples)

catru_samples = load_samples(catru_samples)

chauvan_samples = load_samples(chauvan_samples)

cheo_samples = load_samples(cheo_samples)

hatxam_samples = load_samples(hatxam_samples)

"""### Waveform"""

def plot_waveform(samples, type_index, sr = 22050):
    """
    Waveform plot of samples
    """
    color = random.choice(["blue", "red", "yellow", "brown", "purple"])
    for index, sample in samples.items():
      plt.figure(figsize = (16, 5))
      lb.display.waveshow(y = sample["sampling"], sr = sr, color = color);
      plt.title("Sound Waves of sample {} of class {}".format(index, type_list[type_index][0]), fontsize = 23);

plot_waveform(five_cailuong_samples, 0)

plot_waveform(five_catru_samples, 1)

plot_waveform(five_chauvan_samples, 2)

plot_waveform(five_cheo_samples, 3)

plot_waveform(five_hatxam_samples, 4)

"""### Short Time Fourier Transform"""

def get_fft(samples, n_fft = 2048, hop_length = 512):
    """
    Input: samples: {index: {"dir": "/..."}}
    Output: samples: {index: {"dir": "/...", "stft:" array}}
    """
    for index, item in samples.items():
        # Get STFT
        D = np.abs(lb.stft(item["sampling"], n_fft = n_fft, hop_length = hop_length))
        samples[index]["stft"] = D
    return samples

def plot_fft(samples, type_index):
    """
    Get frequency domain representation
    """
    for index, item in samples.items():
        plt.figure(figsize = (16, 6))
        plt.plot(item["stft"])
        plt.xlabel("Time")
        plt.ylabel("Frequency")
        plt.title("STFT of sample {} of class {}".format(index, type_list[type_index][0]))

"""#### Stft 5 random samples"""

five_cailuong_samples = get_fft(five_cailuong_samples)
plot_fft(five_cailuong_samples, 0)

# Shape of stft matrix (Fre_bins, Num of frames)
# = (n_fft/2 + 1, int(((sampling_arr.length - hop_length))/ frame_size) + 1)
five_cailuong_samples[94]['stft'].shape

five_catru_samples = get_fft(five_catru_samples)
plot_fft(five_catru_samples, 1)

five_chauvan_samples = get_fft(five_chauvan_samples)
plot_fft(five_chauvan_samples, 2)

five_cheo_samples = get_fft(five_cheo_samples)
plot_fft(five_cheo_samples, 0)

five_hatxam_samples = get_fft(five_hatxam_samples)
plot_fft(five_hatxam_samples, 4)

"""#### Stft all samples"""

cailuong_samples = get_fft(cailuong_samples)
catru_samples = get_fft(catru_samples)
chauvan_samples = get_fft(chauvan_samples)
cheo_samples = get_fft(cheo_samples)
hatxam_samples = get_fft(five_hatxam_samples)

"""### Spectrogram"""

def plot_spectrogram(samples, type_index, HOP_LENGTH = 512):
  """
  Plot spectrogram
  """
  for index, item in samples.items():
      DB = lb.amplitude_to_db(item["stft"], ref = np.max)
      plt.figure(figsize = (25, 10))
      lb.display.specshow(DB, hop_length= HOP_LENGTH, x_axis = "time", y_axis = "log")
      plt.title("Spectrogram of sample {} of class {}".format(index, type_list[type_index][0]), fontsize = 20)
      plt.colorbar()

plot_spectrogram(five_cailuong_samples, 0)

plot_spectrogram(five_catru_samples, 1)

plot_spectrogram(five_chauvan_samples, 2)

plot_spectrogram(five_cheo_samples, 3)

plot_spectrogram(five_hatxam_samples, 4)

"""### Mel-Spectrogram"""

def get_mel_spectrogram(samples, type_index, sr = 22050):
    """
    Get log-mel-spectrogram (db)
    Input: {index: {"dir": "/...", "stft": array, }}
    Output: {index: {"dir": "/...", "stft": array, "mel-spec-db": array}}
    """
    for index, item in samples.items():
        S = lb.feature.melspectrogram(y = item["sampling"], sr=sr)
        S_db = lb.amplitude_to_db(S, ref=np.max)
        samples[index]["mel-spec-db"] = S_db
    return samples

"""#### Mel-spec for 5 random samples"""

five_cailuong_samples = get_mel_spectrogram(five_cailuong_samples, 0)
five_catru_samples = get_mel_spectrogram(five_catru_samples, 1)
five_chauvan_samples = get_mel_spectrogram(five_chauvan_samples, 2)
five_cheo_samples = get_mel_spectrogram(five_cheo_samples, 3)
five_hatxam_samples = get_mel_spectrogram(five_hatxam_samples, 4)

def plot_mel_spectrogram(samples, type_index, sr = 22050, HOP_LENGTH = 512):
    """
    Plot log-mel-spectrogram
    """
    for index, item in samples.items():
        S_DB = item["mel-spec-db"]
        plt.figure(figsize = (16, 6))
        lb.display.specshow(S_DB, sr=sr, hop_length = HOP_LENGTH, x_axis = 'time', y_axis = 'log')
        plt.colorbar();
        plt.title("Mel Spectrogram of sample {} of class {}".format(index, type_list[type_index][0]), fontsize = 20)

plot_mel_spectrogram(five_cailuong_samples, 0)

plot_mel_spectrogram(five_catru_samples, 1)

plot_mel_spectrogram(five_chauvan_samples, 2)

plot_mel_spectrogram(five_cheo_samples, 3)

plot_mel_spectrogram(five_hatxam_samples, 4)

"""#### Mel-spectrogram all samples"""

cailuong_samples = get_mel_spectrogram(cailuong_samples, 0)

catru_samples = get_mel_spectrogram(catru_samples, 1)

chauvan_samples = get_mel_spectrogram(chauvan_samples, 2)

cheo_samples = get_mel_spectrogram(cheo_samples, 3)

hatxam_samples = get_mel_spectrogram(hatxam_samples, 4)

hatxam_samples[0]["mel-spec-db"].shape

"""### Save mel-spectrogram for images classification"""

save_root = "/content/drive/MyDrive/DATA"
if not os.path.exists(save_root + "/mel-images"):
    os.makedirs(save_root + "/mel-images")
save_root += "/mel-images"

def save_mel_spec(samples, root, type_index):
    """
    save log-mel-spec
    After running, images of a class will be saved in : root/class/file_name.png
    """
    for index, item in samples.items():
        S_db = item["mel-spec-db"]
        folder_root = str(root) + "/{}".format(type_list[type_index][0])
        if not os.path.exists(folder_root):
            os.makedirs(folder_root)
        # Get file name from fir
        file_name = item["dir"].split("/")[-1][:-4]
        plt.imsave(folder_root + "/{}".format(file_name) + ".png", S_db)

# Save "cailuong" mel-spectrogram at "/content/drive/MyDrive/DATA/mel-images/cailuong
save_mel_spec(cailuong_samples, save_root, 0)

save_mel_spec(catru_samples, save_root, 1)

save_mel_spec(chauvan_samples, save_root, 2)

save_mel_spec(cheo_samples, save_root, 3)

save_mel_spec(hatxam_samples, save_root, 4)

"""## 2) **Split train/val/test**

Split all mel-spectrogram images into train/val/test folder, each folder has images of 5 class
"""

TRAIN_RATE = 0.75
VAL_RATE = 0.15
TEST_RATE = 0.1

from sklearn.model_selection import train_test_split
import shutil

def train_val_test_split(folder_root, dataset_root, type_index):
    """
    Split and save train/val/test set
    Input:
    - folder_root: folder_root containing mel-spec images
    - dataset_root: Directory to save dataset
    - type_root : train_root, val_root or test_root
    - type_index: class index in type_list
    """

    def save_set(subset, dataset_root, typeset, type_index):
      """
      Save X_train, X_val, X_test to their respective dir
      Input:
        - subset - X_train, X_val, X_test
        - dataset_root: Directory to save dataset
        - typeset - train, val, test
        - type index - Class index
      """
      # Copy file from subset to train/val/test folder
      for file in subset:
          srcpath = os.path.join(src_dir, file)
          dst_dir = dataset_root + "/" + typeset + "/{}".format(type_list[type_index][0])
          if not os.path.exists(dst_dir):
              os.makedirs(dst_dir)
          shutil.copy(srcpath, dst_dir)


    src_dir = folder_root + "/{}".format(type_list[type_index][0])
    X = os.listdir(src_dir)
    Y = ["{}".format(type_list[type_index][0]) for i in range(0, len(X))]
    # Train 75%, test 25%
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 1 - TRAIN_RATE, random_state=42, shuffle = True)
    # Val 15 %, test 10%
    X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size = TEST_RATE / (TEST_RATE + VAL_RATE), random_state=42, shuffle = True)

    # Create dataset_root to save dataset
    if not os.path.exists(dataset_root):
        os.makedirs(dataset_root)
    # Save train/val/test of each class
    save_set(X_train, dataset_root, "train", type_index)
    save_set(X_val, dataset_root, "val", type_index)
    save_set(X_test, dataset_root, "test", type_index)

# Train/val/test_split for class "cailuong"
train_val_test_split(folder_root, dataset_root, 0)

# Train/val/test_split for class "catru"
train_val_test_split(folder_root, dataset_root, 1)

# Train/val/test_split for class "chauvan"
train_val_test_split(folder_root, dataset_root, 2)

# Train/val/test_split for class "cheo"
train_val_test_split(folder_root, dataset_root, 3)

# Train/val/test_split for class "hatxam"
train_val_test_split(folder_root, dataset_root, 4)

"""## 3) **Build model for Mel-spectrogram Image Classification**"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
from sklearn.metrics import confusion_matrix
import seaborn as sns
from keras.preprocessing import image
from tensorflow.keras.models import load_model
from tensorflow.keras.utils import plot_model
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.image import img_to_array, load_img

data_dir = "/content/drive/MyDrive/DATA/mel-images"

# Redefine train/val/test set directory after train/val/test split
train_dir = dataset_root + "/" + train_root.split("/")[-1]
val_dir = dataset_root + "/" + val_root.split("/")[-1]
test_dir = dataset_root + "/" + test_root.split("/")[-1]

n_class = 5
input_shape = (128, 1292)
tf.random.set_seed(42)

# Create dataset without data augmentation
non_train_datagen = ImageDataGenerator(rescale = 1./255)
non_val_datagen = ImageDataGenerator(rescale=1./255)
non_test_datagen = ImageDataGenerator(rescale=1./255)
non_train_generator = non_train_datagen.flow_from_directory(
    train_dir,
    target_size=(128, 1292),
    shuffle = True,
    subset='training'
)
non_val_generator = non_val_datagen.flow_from_directory(
    val_dir,
    target_size=(128, 1292),
)
non_test_generator = non_test_datagen.flow_from_directory(
    test_dir,
    target_size=(128,1292),
)

# Create dataset with data augmentation
train_datagen = ImageDataGenerator(rescale = 1./255,
                                   width_shift_range = 0.05, height_shift_range=0.05,
                                    zoom_range = 0.025)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(128, 1292),
    shuffle = True,
    subset='training'
)
val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(128, 1292),
)
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(128,1292),
)

# Define callbacks
early = EarlyStopping(monitor='loss',
    patience= 5,
    verbose= 1,
    mode='auto',
    baseline= None,
    restore_best_weights= True)

# Define checkpoint root to save checkpoint
checkpoint_filepath = dataset_root + "/checkpoint"

# Plot result: Loss and accuracy
def plot_result(history):
    fig, ag = plt.subplots(1,2,figsize = (15,6))
    ag[0].plot(history.history['loss'],label = 'train')
    ag[0].plot(history.history['val_loss'],label = 'test')
    ag[0].legend()
    ag[0].set_title('Loss versus epochs')

    ag[1].plot(history.history['accuracy'],label='train')
    ag[1].plot(history.history['val_accuracy'],label='test')
    ag[1].legend()
    ag[1].set_title('Accuracy versus epochs')
    plt.show()

"""### Helper function for model evaluation"""

test_file_names = non_test_generator.filenames # All file in test set
class_indices = non_test_generator.class_indices  # Class index dic
test_labels = non_test_generator.labels

def predict(file_names, labels, class_list, typeset, model):
    y_pred_index = []
    y_class_pred = []
    for file in file_names:
        file_root = dataset_root + "/" + typeset + "/" + str(file)
        image = load_img(file_root, target_size=(input_shape[0], input_shape[1], 3))
        image_array = img_to_array(image)
        image_array = image_array * 1./255
        input_data = tf.expand_dims(image_array, 0)
        pred = model.predict(input_data, verbose = 0)
        pred_index = np.argmax(np.squeeze(pred))
        y_pred_index.append(pred_index)
        y_class_pred.append(class_list[pred_index])
    print("---Predicted----")
    print("Accuracy on {} set : {}".format(typeset, (labels == y_pred_index).sum()/ len(labels)))
    return y_pred_index, y_class_pred

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import seaborn as sns

def get_cfm(y_pred, labels, class_list, typeset):
    ax= plt.subplot()
    cfm = confusion_matrix(y_pred, labels)
    sns.heatmap(cfm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation

    # labels, title and ticks
    ax.set_xlabel('Predicted labels'); ax.set_ylabel('True labels');
    ax.set_title('Confusion Matrix on {} set'.format(typeset), fontsize = 20);
    ax.xaxis.set_ticklabels(list(class_list.values()))
    ax.yaxis.set_ticklabels(list(class_list.values()))
    plt.show()

"""## Model1

Model 1 architecture
"""

from PIL import Image

# creating a object
im = Image.open(r"/content/drive/MyDrive/DATA/model_images/model1.png")
im.show()

def model1(input_shape = input_shape, n_class = n_class):
    model = tf.keras.models.Sequential([
        #first_convolution
        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(input_shape[0], input_shape[1], 3)),
        tf.keras.layers.MaxPooling2D(2, 2),
        #second_convolution
        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        #third_convolution
        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        #fourth_convolution
        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(256, activation='relu'),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(n_class, activation='softmax')
    ])
    if not os.path.exists(checkpoint_filepath + '/model1'):
        os.makedirs(checkpoint_filepath + '/model1')
    checkpoint1= tf.keras.callbacks.ModelCheckpoint(
    filepath= checkpoint_filepath + '/model1' + '/model1_{epoch:02d}_{val_accuracy:.4f}.h5',
    monitor='val_accuracy',
    save_best_only=True,
    save_weights_only=True,
    verbose=1
    )
    return model, checkpoint1
non_model1, checkpoint1 = model1(input_shape, n_class)
non_model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=["accuracy"])
non_model1.summary()

if not os.path.exists(dataset_root + "/checkpoint"):
    os.makedirs(dataset_root + "/checkpoint")
if not os.path.exists(checkpoint_filepath):
    os.makedirs(checkpoint_filepath)
if not os.path.exists(checkpoint_filepath + '/model1'):
    os.makedirs(checkpoint_filepath + '/model1')

plot_model(non_model1)

if tf.test.gpu_device_name():
  print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))
else:
  print("Please install GPU version of TF")

# Fit with non-augmented data
non_model1_history = non_model1.fit(non_train_generator, batch_size= 32, epochs = 20, callbacks=[early, checkpoint1],
                   validation_data = non_val_generator, validation_batch_size = 32)

"""### Evaluate best model1"""

from tensorflow.keras.preprocessing.image import img_to_array, load_img

best_model1, _ = model1(input_shape = input_shape, n_class = n_class)
checkpoint_model1_path = checkpoint_filepath + "/model1"
best_model1_path =  checkpoint_model1_path + "/" + str(os.listdir(checkpoint_model1_path)[-1])
best_model1.load_weights(best_model1_path)
best_model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=["accuracy", tf.keras.metrics.Precision(),  tf.keras.metrics.Recall()])

loss_val1, acc_val1, pre_val1, recall_val1 = best_model1.evaluate(non_val_generator)

loss1, acc1, precision1, recall1 = best_model1.evaluate(non_test_generator)

# Plot result
plot_result(non_model1_history)

best_model1.save(saved_model_path + '/best_model1.h5')

y1_pred, y1_class = predict(test_file_names, test_labels, class_list, "test", best_model1)

get_cfm(y1_pred, test_labels, class_list, "test")

"""### Fit model1 with augmentated data"""

aug_model1, checkpoint_aug1 = model1(input_shape, n_class)
aug_model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=["accuracy"])
aug_model1.summary()

aug_model1_history = aug_model1.fit(train_generator, batch_size= 32, epochs = 80, callbacks=[early, checkpoint_aug1],
                   validation_data = val_generator, validation_batch_size = 32)

aug_model1.evaluate(val_generator)

aug_model1.evaluate(test_generator)

aug_model1.save(dataset_root + '/aug_model1.h5')

aug_model1 = tf.keras.models.load_model(dataset_root + '/aug_model1.h5')

au1_pred, au1_class = predict(test_file_names, test_labels, class_list, "test", aug_model1)

get_cfm(au1_pred, test_labels, class_list, "test")

"""## Model 2

Model2 architecture:
"""

im2 = Image.open(r"/content/drive/MyDrive/DATA/model_images/model2.png")
im2.show()

# Define model2
def model2(input_shape = input_shape, n_class = n_class):
    model2= tf.keras.Sequential(layers=[
            tf.keras.layers.InputLayer(input_shape= (input_shape[0], input_shape[1], 3)),
            tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation="relu"),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation="relu"),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation="relu"),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(64, activation="relu"),
            tf.keras.layers.Dense(n_class, activation="softmax")
        ])
    if not os.path.exists(checkpoint_filepath + '/model2'):
        os.makedirs(checkpoint_filepath + '/model2')
    checkpoint2= tf.keras.callbacks.ModelCheckpoint(
    filepath= saved_model_path + '/model2' + '/model2_{epoch:02d}_{val_accuracy:.4f}.h5',
    monitor='val_accuracy',
    save_best_only=True,
    save_weights_only=True,
    verbose=1
    )
    return model2, checkpoint2
non_model2, checkpoint2 = model2(input_shape, n_class)
non_model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=["accuracy"])
non_model2.summary()

non_model2_history = non_model2.fit(non_train_generator, batch_size=32, epochs= 20, callbacks=[early, checkpoint2], shuffle=True,
                   validation_data = non_val_generator, validation_batch_size = 32)

"""### Evaluate best model2"""

best_model2, _ = model2(input_shape = input_shape, n_class = n_class)
checkpoint_model2_path = checkpoint_filepath + "/model2"
best_model2_path =  checkpoint_model2_path + "/" + str(os.listdir(checkpoint_model2_path)[-1])
best_model2.load_weights(best_model2_path)
best_model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=["accuracy", tf.keras.metrics.Precision(),  tf.keras.metrics.Recall()], run_eagerly=True)

checkloss2, acc2, precision2, recall2 = best_model2.evaluate(non_val_generator)

loss2_test, acc2_test, precision2_test, recall2_test = best_model2.evaluate(non_test_generator)

y2_pred, y2_class = predict(test_file_names, test_labels, class_list, "test", best_model2)

get_cfm(y2_pred, test_labels, class_list, "test")

plot_result(non_model2_history)

best_model2.save(saved_model_path + '/best_model2.h5')

"""### Fit model2 with augmented data"""

aug_model2 = model2(input_shape=input_shape, n_class = n_class)
aug_model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=["accuracy"])
aug_model2.summary()

aug_model2_history =aug_model2.fit(train_generator, batch_size=32, epochs= 80, callbacks=[early], shuffle=True,
                   validation_data = val_generator, validation_batch_size = 32)

"""## Model 3

Model 3 architecture:
"""

im3 = Image.open(r"/content/drive/MyDrive/DATA/model_images/model3.png")
im3.show()

def model3(input_shape = input_shape, n_class = n_class):
      model = tf.keras.models.Sequential([
      #first_convolution
      tf.keras.layers.Conv2D(16, (5,5), activation='relu', input_shape=(input_shape[0], input_shape[1], 3)),
      tf.keras.layers.MaxPooling2D(2, 2),
      #second_convolution
      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
      tf.keras.layers.MaxPooling2D(2,2),
      #third_convolution
      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
      tf.keras.layers.MaxPooling2D(2,2),
      #fourth_convolution
      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
      tf.keras.layers.MaxPooling2D(2,2),
      #Output layers
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dropout(0.2),
      tf.keras.layers.Dense(512, activation='relu'),
      tf.keras.layers.Dropout(0.2),
      tf.keras.layers.BatchNormalization(),
      tf.keras.layers.Dense(128, activation='relu'),
      tf.keras.layers.Dropout(0.2),
      tf.keras.layers.BatchNormalization(),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dropout(0.2),
      tf.keras.layers.BatchNormalization(),
      tf.keras.layers.Dense(n_class, activation='softmax')])

      if not os.path.exists(checkpoint_filepath + "/model3"):
          os.makedirs(checkpoint_filepath + "/model3")
      checkpoint3= tf.keras.callbacks.ModelCheckpoint(
      filepath= checkpoint_filepath + '/model3' + '/model3_{epoch:02d}_{val_accuracy:.4f}.h5',
      monitor='val_accuracy',
      save_best_only=True,
      save_weights_only=True,
      verbose=1
      )
      return model, checkpoint3
non_model3, checkpoint3 = model3(input_shape, n_class)
non_model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=["accuracy"])
non_model3.summary()

non_model3_history = non_model3.fit(non_train_generator, batch_size=32, epochs= 20, callbacks=[early, checkpoint3], shuffle=True,
                   validation_data = non_val_generator, validation_batch_size = 32)

"""### Evaluate best model 3"""

best_model3, _ = model3(input_shape = input_shape, n_class = n_class)
checkpoint_model3_path = checkpoint_filepath + "/model3"
best_model3_path =  checkpoint_model3_path + "/" + str(os.listdir(checkpoint_model3_path)[-1])
best_model3.load_weights(best_model3_path)
best_model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=["accuracy", tf.keras.metrics.Precision(),  tf.keras.metrics.Recall()])

loss3, acc3, pre3, recall3 = best_model3.evaluate(non_val_generator)

loss3_test, acc3_test, pre3_test, recall3_test = best_model3.evaluate(non_test_generator)

y3_pred, y3_class = predict(test_file_names, test_labels, class_list, "test", best_model3)

get_cfm(y3_pred, test_labels, class_list, "test") # Not good

best_model3.save(saved_model_path + '/best_model3.h5')

"""## 5) Predict new audio"""

def predict_new30s(audio_dir, model, save_dir = "/content/drive/MyDrive/DATA/test_images"):
    """
    Predict new 30s-length audio
    Input:
    - audio_dir : List of audios directory (.wav)
    - model: model to predict
    - save_dir: "/content/drive/MyDrive/DATA/test_images" - directory save log-mel-spec image of new audio
    """

    y_pred = []
    y_class = []

    for dir in audio_dir:
        load_dir, sr = lb.load(dir)
        S = lb.feature.melspectrogram(y = load_dir, sr=sr)
        S_db = lb.amplitude_to_db(S, ref=np.max)

        if not os.path.exists(save_dir):
            os.makedirs(save_dir)

        audio_file_name = dir.split("/")[-1][:-4]

        saved_img_root = save_dir + "/{}".format(audio_file_name) + ".png"
        plt.imsave(saved_img_root, S_db)

        image = load_img(saved_img_root, target_size=(input_shape[0], input_shape[1], 3))
        image_array = img_to_array(image)
        input_data = tf.expand_dims(image_array, 0)
        pred = model.predict(input_data, verbose = 0)
        pred_index = np.argmax(np.squeeze(pred))
        y_pred.append(pred_index)
        y_class.append(class_list[pred_index])

        return y_pred, y_class, pred

y_pred, y_class, pred = predict_new30s(["/content/drive/MyDrive/DATA/VNTM3/chauvan/Chauvan.044.wav"], best_model2)

y_pred

y_class

pip install pydub

from pydub import AudioSegment

def predict_new(audio_dir, model, save_dir, unit_length = 661500):
    """
    Predict audio of any length
    Split each audio into several equal sample which length = unit_length, then feed to NN
    Get predict class by most votting of each sample's prediction

    Input:
    - audio_dir: List of audio directory to predict
    - model: Model to predict
    - save_dir: Directory to save log-mel-spec image of samples splitted from each audio in audio_dir
    Output:
    - y_pred_index: List of index predicted of each audio in audio_dir
    - y_pred_class: Respective class predicted of y_pred_index
    """
    def mp3_2_wav(dir, dst, sample_rate = 22050):
        """
        Convert mp3 to wav and save wav file to dst
        Input: dir (mp3)
        """
        # convert wav to mp3.
        sound = AudioSegment.from_mp3(dir)
        sound.set_frame_rate(sample_rate)
        sound.export(dst, format="wav")


    def process(samples_split, save_dir, file_name, is_saved):
        """
        End to end processing steps of each audio

        Input:
        - samples_split: List of samples splitted from each audio in audio_dir
        - save_dir: Directory to save log-mel-spec image of samples splitted from each audio in audio_dir
        - is_save: If False, do not save log-mel-spec image of samples, just make prediction

        Output:
        - np.array(samples_db_list): A batch of samples of each audio file (nums_of_sample, input_shape[0], input_shape[1], 3) to feed to NN
        """
        samples_db_list = []
        for i, sample in enumerate(samples_split):
            S = lb.feature.melspectrogram(y = sample, sr=sr)
            S_db = lb.amplitude_to_db(S, ref=np.max)
            if not os.path.exists(save_dir):
                os.makedirs(save_dir)
            sample_root = save_dir + "/{}".format(file_name) + "_sample{}".format(i) + ".png"
            plt.imsave(sample_root, S_db)
            image = load_img(sample_root, target_size=(input_shape[0], input_shape[1], 3))
            img_array = img_to_array(image)
            img_array = img_array / 255
            samples_db_list.append(img_array)
            if not is_saved: # Not save mode
                for file in os.listdir(save_dir):
                    if file.endswith('.png'):
                        os.remove(save_dir + '/' + file)
        return np.array(samples_db_list)

    # Define result
    y_pred_index = []
    y_pred_class = []

    # List of samples of each audio
    samples_split = []
    y_pred_split = []

    for dir in audio_dir:
        if dir.endswith(".mp3"):
            # Get file name
            wav_dir = test_audio_path + "/" + dir.split("/")[-1][:-4] + ".wav"
            mp3_2_wav(dir, wav_dir)
            dir = wav_dir       # Take wav dir for sampling

        audio, sr = lb.load(dir)
        if (len(audio) >= unit_length):
            # Number of sample of each audio
            nums_of_samples = len(audio) // unit_length
        else:
            err = "Audio length must be greater than 30s"
            print(err)
            return err
        for i in range(0, nums_of_samples):
            curr_sample = audio[i * unit_length : i * unit_length + unit_length]
            if (len(curr_sample) != unit_length): # Cannot sampling this curr_sample
                break
            samples_split.append(audio[i * unit_length : i * unit_length + unit_length])

        file_name = dir.split("/")[-1][:-4]

        input_data = process(samples_split, save_dir, file_name, False)

        pred_candidates = model.predict(input_data, verbose = 0)

        pred_index_candidates = [np.argmax(sample) for sample in pred_candidates]

        pred_index = max(pred_index_candidates, key = pred_index_candidates.count)
        pred_class = class_list[pred_index]

        y_pred_index.append(pred_index)
        y_pred_class.append(pred_class)

        # Reset samples_split after passing one dir of audio_dir
        samples_split = []

    return y_pred_index, y_pred_class

"""### Let's predict new audio"""

hatxam_test = ["/content/drive/MyDrive/DATA/test_audio/XamXoanTrongQuan-HaThiCau-HATXAM.mp3",
               "/content/drive/MyDrive/DATA/test_audio/XamXoanTrongQuan-HaThiCau-HATXAM.mp3",
               "/content/drive/MyDrive/DATA/test_audio/XamHueTinh-HaThiCau-2595212.wav",
               "/content/drive/MyDrive/DATA/test_audio/ThuocPhien-HaThiCau-HATXAM.mp3",
               "/content/drive/MyDrive/DATA/test_audio/Hatxam-Nhoinay-HaThiCau-HATXAM.mp3"]

# model1 predict
predict_new(hatxam_test, best_model1, "/content/drive/MyDrive/DATA/test_images")

# model2 predict
predict_new(hatxam_test, best_model2, "/content/drive/MyDrive/DATA/test_images")

# model3 predict
predict_new(hatxam_test, best_model3, "/content/drive/MyDrive/DATA/test_images")

cheo_test = ["/content/drive/MyDrive/DATA/test_audio/TinhThuHaVi-QuocPhong-CHEO.mp3",
             "/content/drive/MyDrive/DATA/test_audio/NonThungQuaiThao-CHEO.mp3",
             "/content/drive/MyDrive/DATA/test_audio/TrinhPhu-DangCapNhat-CHEO.mp3",
             "/content/drive/MyDrive/DATA/test_audio/DuongTruongTiengDan-CHEO.mp3",
             "/content/drive/MyDrive/DATA/test_audio/DaoLieu-VanChuongNSUT-CHEO.mp3"]
predict_new(cheo_test, best_model2, "/content/drive/MyDrive/DATA/test_images")

predict_new(cheo_test, best_model1, "/content/drive/MyDrive/DATA/test_images")

predict_new(cheo_test, best_model2, "/content/drive/MyDrive/DATA/test_images")

predict_new(cheo_test, best_model3, "/content/drive/MyDrive/DATA/test_images")

cailuong_test = ["/content/drive/MyDrive/DATA/test_audio/DieuHoQuang-TrangThuDaKhuc-CAILUONG.mp3",
                 "/content/drive/MyDrive/DATA/test_audio/DuyenKiepTanCoGiaoDuyen-MinhVuon_3eu59.mp3",
                 "/content/drive/MyDrive/DATA/test_audio/LenhTruyNa-VuongLinh-CAILUONG.mp3",
                 "/content/drive/MyDrive/DATA/test_audio/Tinhyeuvagiotnuocmat-NguyenKha-CAILUONG.mp3",
                 "/content/drive/MyDrive/DATA/test_audio/Bepluachieulybiet-CAILUONG.mp3"]

predict_new(cailuong_test, best_model1, "/content/drive/MyDrive/DATA/test_images")

predict_new(cailuong_test, best_model2, "/content/drive/MyDrive/DATA/test_images")

predict_new(cailuong_test, best_model3, "/content/drive/MyDrive/DATA/test_images")

catru_test = ["/content/drive/MyDrive/DATA/test_audio/loithenonnuoc_catru.mp3",
              "/content/drive/MyDrive/DATA/test_audio/TuongTienTuu-QuachThiHo-CATRU.wav",
              "/content/drive/MyDrive/DATA/test_audio/HuongSonPhongCanhCa_CaTru.mp3",
              ]

predict_new(catru_test, best_model1, "/content/drive/MyDrive/DATA/test_images")

predict_new(catru_test, best_model2, "/content/drive/MyDrive/DATA/test_images")

predict_new(catru_test, best_model3, "/content/drive/MyDrive/DATA/test_images")

chauvan_test = ["/content/drive/MyDrive/DATA/test_audio/CoChin-ThanhNgoanKhacTu-CHAUVAN.mp3",
                "/content/drive/MyDrive/DATA/test_audio/CauBeDoiNgang-VanChuong-CHAUVAN.mp3",
                "/content/drive/MyDrive/DATA/test_audio/ThinhMauVaQuanDeNhat-CHAUVAN.mp3",
                "/content/drive/MyDrive/DATA/test_audio/BaChuaThac-ChauVan-ThanhNgoan-CHAUVAN.mp3",
                "/content/drive/MyDrive/DATA/test_audio/VanChauMuoi-CHAUVAN.mp3"]

predict_new(chauvan_test, best_model1, "/content/drive/MyDrive/DATA/test_images") # Not good

predict_new(chauvan_test, best_model2, "/content/drive/MyDrive/DATA/test_images") # Very good

predict_new(chauvan_test, best_model3, "/content/drive/MyDrive/DATA/test_images") # Quite good